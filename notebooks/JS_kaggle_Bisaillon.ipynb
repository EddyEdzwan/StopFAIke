{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38801612",
   "metadata": {},
   "source": [
    "# Kaggle Bisaillon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e548287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize \n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de7d9e9",
   "metadata": {},
   "source": [
    "## Loading `csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a468cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "true shape: (21417, 4)\n",
      "fake shape: (23481, 4)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "true_filepath = '../raw_data/kaggle_Bisaillon/True.csv'\n",
    "fake_filepath = '../raw_data/kaggle_Bisaillon/Fake.csv'\n",
    "\n",
    "true = pd.read_csv(true_filepath)\n",
    "fake = pd.read_csv(fake_filepath)\n",
    "\n",
    "print('-'*80)\n",
    "print(f\"true shape: {true.shape}\")\n",
    "print(f\"fake shape: {fake.shape}\")\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db435a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbdaf09",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e40ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_duplicate(df):\n",
    "    return df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db04408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "true duplicates: 206\n",
      "fake duplicates: 3\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*80)\n",
    "print(f\"true duplicates: {count_duplicate(true)}\")\n",
    "print(f\"fake duplicates: {count_duplicate(fake)}\")\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "740b58d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "true shape (wo duplicates): (21211, 4)\n",
      "fake shape (wo duplicates): (23478, 4)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "true.drop_duplicates(inplace=True)\n",
    "fake.drop_duplicates(inplace=True)\n",
    "\n",
    "print('-'*80)\n",
    "print(f\"true shape (wo duplicates): {true.shape}\")\n",
    "print(f\"fake shape (wo duplicates): {fake.shape}\")\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eba03c",
   "metadata": {},
   "source": [
    "### Merging the `true` / `fake` dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87735919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "data shape: (44689, 6)\n",
      "--------------------------------------------------------------------------------\n",
      "ratio #true: 47.46%\n",
      "ratio #false: 52.54%\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "true['category'] = 0\n",
    "fake['category'] = 1\n",
    "\n",
    "data = pd.concat([true, fake]).reset_index()\n",
    "\n",
    "print('-'*80)\n",
    "print(f\"data shape: {data.shape}\")\n",
    "print('-'*80)\n",
    "print(f\"ratio #true: {len(data[data['category']==0])/len(data)*100:.2f}%\")\n",
    "print(f\"ratio #false: {len(data[data['category']==1])/len(data)*100:.2f}%\")\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d1dca35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=data.category);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faf505f",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0d4c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing(df):\n",
    "    missing_values = df.isnull().sum().sort_values(ascending = False)\n",
    "    ratio = missing_values/len(data)*100\n",
    "    return pd.DataFrame({'missing_values': missing_values, 'ratio': round(ratio)}).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a0f87c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_values</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          missing_values  ratio\n",
       "index                  0    0.0\n",
       "title                  0    0.0\n",
       "text                   0    0.0\n",
       "subject                0    0.0\n",
       "date                   0    0.0\n",
       "category               0    0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_missing(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db475d",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ef1dcac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "politicsNews       11220\n",
       "worldnews           9991\n",
       "News                9050\n",
       "politics            6838\n",
       "left-news           4459\n",
       "Government News     1570\n",
       "US_News              783\n",
       "Middle-east          778\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.subject.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9e1bf",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7531283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean (text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ') # Remove Punctuation\n",
    "    lowercased = text.lower() # Lower Case\n",
    "    tokenized = word_tokenize(lowercased) # Tokenize\n",
    "    words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "    stop_words = set(stopwords.words('english')) # Make stopword list\n",
    "    without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words\n",
    "    lemma=WordNetLemmatizer() # Initiate Lemmatizer\n",
    "    lemmatized = [lemma.lemmatize(word) for word in without_stopwords] # Lemmatize\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a3176a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              title  \\\n",
       "0      0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1      1  U.S. military to accept transgender recruits o...   \n",
       "2      2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3      3  FBI Russia probe helped by Australian diplomat...   \n",
       "4      4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  category  \n",
       "0  December 31, 2017          0  \n",
       "1  December 29, 2017          0  \n",
       "2  December 31, 2017          0  \n",
       "3  December 30, 2017          0  \n",
       "4  December 29, 2017          0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcde56ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to all texts\n",
    "data['clean_text'] = data.text.apply(clean)\n",
    "# data['clean_text'] = data['clean_text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "982c5ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>[washington, reuters, head, conservative, repu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>[washington, reuters, transgender, people, all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>[washington, reuters, special, counsel, invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>[washington, reuters, trump, campaign, adviser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>[seattle, washington, reuters, president, dona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              title  \\\n",
       "0      0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1      1  U.S. military to accept transgender recruits o...   \n",
       "2      2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3      3  FBI Russia probe helped by Australian diplomat...   \n",
       "4      4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  category  \\\n",
       "0  December 31, 2017          0   \n",
       "1  December 29, 2017          0   \n",
       "2  December 31, 2017          0   \n",
       "3  December 30, 2017          0   \n",
       "4  December 29, 2017          0   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [washington, reuters, head, conservative, repu...  \n",
       "1  [washington, reuters, transgender, people, all...  \n",
       "2  [washington, reuters, special, counsel, invest...  \n",
       "3  [washington, reuters, trump, campaign, adviser...  \n",
       "4  [seattle, washington, reuters, president, dona...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b2f3b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.loc[0, 'clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54715c7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dcd5396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "X shape: (44689, 1)\n",
      "y shape: (44689, 1)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = data[['clean_text']].copy()\n",
    "y = data[['category']].copy()\n",
    "\n",
    "print('-'*80)\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f99b6fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "X_train shape: (31282, 1)\n",
      "y_train shape: (31282, 1)\n",
      "--------------------------------------------------------------------------------\n",
      "X_test shape: (13407, 1)\n",
      "y_test shape: (13407, 1)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print('-'*80)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print('-'*80)\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ff9ae",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf518827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# This initializes a Keras utilities that does all the tokenization for you\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# The tokenization learns a dictionnary that maps a token (integer) to each word\n",
    "# It can be done only on the train set - we are not supposed to know the test set !\n",
    "# This tokenization also lower your words, apply some filters, and so on - you can check the doc if you want\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "# We apply the tokenization to the train and test set\n",
    "X_train_token = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_token = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "print('-'*80)\n",
    "print(f\"X_train_token shape: {len(X_train_token)}\")\n",
    "print(f\"X_test_token shape: {len(X_test_token)}\")\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422cd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)\n",
    "\n",
    "print('-'*80)\n",
    "print(f\"vocab_size: {vocab_size}\")\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f4a90e",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d487b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post')\n",
    "# X_test_pad = pad_sequences(X_test_token, maxlen=X_train_pad.shape[1], dtype='float32', padding='post')\n",
    "\n",
    "print('-'*80)\n",
    "print(f\"X_train_pad shape: {X_train_pad.shape}\")\n",
    "print(f\"y_train shape: {len(y_train)}\")\n",
    "print('-'*80)\n",
    "print(f\"X_test_pad shape: {X_test_pad.shape}\")\n",
    "print(f\"y_test shape: {len(y_test)}\")\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7af2098",
   "metadata": {},
   "source": [
    "### Model - embedding layer included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "\n",
    "    embedding_size = 5\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(\n",
    "        input_dim = vocab_size+1,\n",
    "        input_length = 4958, # Max_sentence_length (optional, for model summary)\n",
    "        output_dim = embedding_size,# 100\n",
    "        mask_zero = True, # Included masking layer :)\n",
    "    ))\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(20, activation='tanh'))\n",
    "    model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5834293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model = init_model()\n",
    "\n",
    "history = model.fit(X_train_pad, \n",
    "                  y_train,\n",
    "                  validation_split=0.2,\n",
    "                  batch_size=64,\n",
    "                  epochs=2, \n",
    "                  callbacks=[es],\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, title=None):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(13,4))\n",
    "    ax1.plot(history.history['loss'])\n",
    "    ax1.plot(history.history['val_loss'])\n",
    "    ax1.set_title('Model loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylim(ymin=0, ymax=1)\n",
    "    ax1.legend(['Train', 'Validation'], loc='best')\n",
    "\n",
    "    ax2.plot(history.history['accuracy'])\n",
    "    ax2.plot(history.history['val_accuracy'])\n",
    "    ax2.set_title('ACC')\n",
    "    ax2.set_ylabel('ACC')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylim(ymin=0, ymax=1)\n",
    "    ax2.legend(['Train', 'Validation'], loc='best')\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b159d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history, title=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05311ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test_pad, y_test)\n",
    "\n",
    "print('-'*80)\n",
    "print(f\"test score (MAPE): {results[1]:.3f}\")\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151ee2c",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b45571e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you must first build vocabulary before training the model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wt/qw732brs7m799f67rntt1n180000gn/T/ipykernel_44454/1152254143.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0munique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/StopFAIke/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab)\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             self.train(\n\u001b[0m\u001b[1;32m    420\u001b[0m                 \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/StopFAIke/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_training_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/StopFAIke/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_check_training_sanity\u001b[0;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# should be set by `build_vocab`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must first build vocabulary before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must initialize vectors before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec(sentences=X_train, vector_size=10, min_count=10, window=10)\n",
    "\n",
    "unique = set([_ for elt in X_train for _ in elt])\n",
    "\n",
    "# print('-'*80)\n",
    "# print(f\"X_train vocabulary size: {len(unique)}\")\n",
    "# print(f\"word2vec vocabulary size: {len(word2vec.wv.key_to_index)}\")    \n",
    "# print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214a00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c2fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(word2vec, sentence):\n",
    "    embed_matrix = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv.key_to_index:\n",
    "            embed_matrix.append(word2vec.wv[word])\n",
    "    return np.array(embed_matrix)\n",
    "\n",
    "def embedding(word2vec, sentences):\n",
    "    return [embed_sentence(word2vec, sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33eafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed = embedding(word2vec, X_train[0])\n",
    "X_test_embed = embedding(word2vec, X_test[0])\n",
    "\n",
    "X_train_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c161636",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post')\n",
    "# X_test_pad = pad_sequences(X_test_token, maxlen=X_train_pad.shape[1], dtype='float32', padding='post')\n",
    "\n",
    "print('-'*80)\n",
    "print(f\"X_train_pad shape: {X_train_pad.shape}\")\n",
    "print(f\"y_train shape: {len(y_train)}\")\n",
    "print('-'*80)\n",
    "print(f\"X_test_pad shape: {X_test_pad.shape}\")\n",
    "print(f\"y_test shape: {len(y_test)}\")\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3f27a6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd68d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "\n",
    "    embedding_size = 5\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(20, activation='tanh'))\n",
    "    model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7c51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model = init_model()\n",
    "\n",
    "history = model.fit(X_train_pad, \n",
    "                  y_train,\n",
    "                  validation_split=0.2,\n",
    "                  batch_size=64,\n",
    "                  epochs=2, \n",
    "                  callbacks=[es],\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3981298c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e6e96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926cad09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8ff4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6888ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
